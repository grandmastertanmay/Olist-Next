{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76994666-6312-4b8b-8ffa-9b709baa3f12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ü§ñ Phase 4: Churn Prediction Model (PySpark ML + MLflow)\n",
    "**Project:** \"Olist-Next\" Retention Engine\n",
    "**Target:** `is_churn_risk` (1 = At Risk, 0 = Retained)\n",
    "\n",
    "## üß† Modeling Strategy\n",
    "We are training a **Random Forest Classifier** to predict churn probability.\n",
    "* **Leakage Prevention:** We explicitly **DROP** `recency_days` and `last_purchase_date`. These columns were used to *create* the target label, so using them as features would be cheating (Data Leakage).\n",
    "* **Feature Engineering:** We use a `Pipeline` to index and encode the categorical column (`favorite_category`) and assemble numerical features.\n",
    "* **Governance:** The training is tracked by **MLflow**, and the final model is registered to **Unity Catalog**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41060732-4d03-4494-8621-623eed757a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup & Data Loading \n",
    "Load the Gold data and enforce the strict leakage prevention constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42a9780a-facf-4f97-adb9-83ed96c4705c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import mlflow\n",
    "\n",
    "# Set Context\n",
    "spark.sql(\"USE CATALOG olist_hackathon\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS ml_models\")\n",
    "\n",
    "# 1. Load Gold Table\n",
    "df_gold = spark.table(\"gold.customer_360\")\n",
    "\n",
    "# 2. Select Features & Target (STRICT LEAKAGE PREVENTION)\n",
    "# We deliberately exclude 'recency_days' and 'last_purchase_date'\n",
    "feature_cols = [\"frequency\", \"monetary_value\", \"avg_review_score\", \"favorite_category\"]\n",
    "target_col = \"is_churn_risk\"\n",
    "\n",
    "df_ml = df_gold.select(feature_cols + [target_col])\n",
    "\n",
    "# 3. Split Data (80% Train, 20% Test)\n",
    "# Seed 42 ensures reproducibility\n",
    "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"‚úÖ Data Loaded.\")\n",
    "print(f\"   Training Rows: {train_df.count()}\")\n",
    "print(f\"   Testing Rows:  {test_df.count()}\")\n",
    "print(f\"   Leakage columns dropped? YES.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ee2bc43-32c7-4d6e-9e37-9cc0ac455b13",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Step 1: Filter single-value categorical columns"
    }
   },
   "outputs": [],
   "source": [
    "# Identify categorical columns (assuming string type)\n",
    "categorical_columns = [\n",
    "    col_name for col_name in train_df.columns\n",
    "    if train_df.schema[col_name].dataType.simpleString() == \"string\"\n",
    "]\n",
    "\n",
    "# Exclude columns with only one unique value\n",
    "filtered_categorical_columns = [\n",
    "    col for col in categorical_columns\n",
    "    if train_df.select(col).distinct().count() > 1\n",
    "]\n",
    "\n",
    "print(\"Filtered categorical columns for encoding:\", filtered_categorical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5047432-224b-40a0-9150-2f4ce5248d4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### The ML Pipeline Construction \n",
    "Define the stages: Indexer -> Encoder -> Assembler -> Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a1f3d4a-4a08-4f10-a330-37d60c2174cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 5"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Stage 1: Convert filtered categorical columns to indices\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in filtered_categorical_columns]\n",
    "\n",
    "# Stage 2: One-Hot Encode the indices\n",
    "encoders = [OneHotEncoder(inputCols=[f\"{col}_index\"], outputCols=[f\"{col}_vec\"]) for col in filtered_categorical_columns]\n",
    "\n",
    "# Stage 3: Assemble all features into a single 'features' vector\n",
    "# Numerical features + all categorical vectors\n",
    "assembler_inputs = [col for col in [\"frequency\", \"monetary_value\", \"avg_review_score\"]]\n",
    "assembler_inputs += [f\"{col}_vec\" for col in filtered_categorical_columns]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=assembler_inputs,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Stage 4: The Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"is_churn_risk\", \n",
    "    featuresCol=\"features\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create the Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
    "\n",
    "print(\"‚úÖ ML Pipeline constructed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9205e9a8-9c28-4de5-b0fc-ee1fa4b99e81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Training & MLflow Tracking (Python)\n",
    "Train the model, evaluate it, and log everything to MLflow in one atomic block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcdb154a-53ba-49ef-ad40-b3f568b28de8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create the temporary schema required by MLflow for staging\n",
    "CREATE SCHEMA IF NOT EXISTS olist_hackathon.tmp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a90965-e374-4610-a3e8-4d00e9be9ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create the volume required for MLflow artifact logging\n",
    "CREATE VOLUME IF NOT EXISTS olist_hackathon.tmp.mlflow;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa72d07-f0e6-4cc5-b065-23e6f058806c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Training & MLflow Tracking (Python)"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Define Experiment Path (Optional: organizes runs in the UI)\n",
    "experiment_name = \"/Users/your_email@databricks.com/olist_churn_experiment\"\n",
    "# mlflow.set_experiment(experiment_name) # Uncomment if you want a specific path\n",
    "\n",
    "print(\"‚è≥ Starting Training Run...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Olist_RF_PySpark\") as run:\n",
    "    \n",
    "    # 1. Train the Model (Fit the Pipeline)\n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    # 2. Make Predictions on Test Data\n",
    "    predictions = model.transform(test_df)\n",
    "    \n",
    "    # 3. Evaluate Metrics\n",
    "    # AUC (Area Under ROC) - Standard for Binary Classification\n",
    "    binary_evaluator = BinaryClassificationEvaluator(labelCol=\"is_churn_risk\", metricName=\"areaUnderROC\")\n",
    "    auc = binary_evaluator.evaluate(predictions)\n",
    "    \n",
    "    # F1 Score - Balances Precision and Recall (Important for Imbalanced Data)\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_churn_risk\", metricName=\"f1\")\n",
    "    f1_score = multi_evaluator.evaluate(predictions)\n",
    "    \n",
    "    print(f\"üìä Evaluation Metrics:\")\n",
    "    print(f\"   AUC: {auc:.4f}\")\n",
    "    print(f\"   F1 Score: {f1_score:.4f}\")\n",
    "    \n",
    "    # 4. Log to MLflow\n",
    "    mlflow.log_param(\"num_trees\", 50)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score)\n",
    "    \n",
    "    # 5. Infer model signature\n",
    "    signature = infer_signature(train_df.toPandas(), predictions.toPandas())\n",
    "    \n",
    "    # 6. Log the Spark Model\n",
    "    # This saves the entire pipeline (feature engineering + model)\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"olist_hackathon.ml_models.churn_predictor\", # Registers automatically to UC\n",
    "        dfs_tmpdir=\"/Volumes/olist_hackathon/tmp/mlflow/\", # <-- UC volume path required for serverless clusters\n",
    "        signature=signature\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Run Complete. Model logged and registered.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "654d6bfb-dc37-4b03-98ae-54422203c3a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Validation (Python)\n",
    "Load the model back from the registry to prove it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ae51465-e514-4a4c-b172-5cc0987d90a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify Model Registration"
    }
   },
   "outputs": [],
   "source": [
    "# Verify Model Registration\n",
    "model_name = \"olist_hackathon.ml_models.churn_predictor\"\n",
    "print(f\"üîç Verifying model: {model_name}...\")\n",
    "\n",
    "# Load the registered model WITH the required volume path\n",
    "loaded_model = mlflow.spark.load_model(\n",
    "    f\"models:/{model_name}/1\",\n",
    "    dfs_tmpdir=\"/Volumes/olist_hackathon/tmp/mlflow/\" # <-- The Fix\n",
    ")\n",
    "\n",
    "# Test on a small sample\n",
    "sample_pred = loaded_model.transform(test_df.limit(5))\n",
    "display(sample_pred.select(\"favorite_category\", \"frequency\", \"prediction\", \"probability\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01a90666-0e90-4c05-a787-118103e7d92f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7322293860832719,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_ML_Churn_Prediction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
